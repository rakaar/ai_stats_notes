{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e77cbb6-ef46-4225-9398-bdcfa1a45594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b2a925a-7d74-4c04-a5db-e39238039338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-04-02 21:11:00--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8000::154, 2606:50c0:8001::154, 2606:50c0:8002::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8000::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1115394 (1.1M) [text/plain]\n",
      "Saving to: ‘input.txt’\n",
      "\n",
      "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.08s   \n",
      "\n",
      "2024-04-02 21:11:00 (13.2 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We always start with a dataset to train on. Let's download the tiny shakespeare dataset\n",
    "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53dbd23d-8c96-495e-9a27-985a49768e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read it in to inspect it\n",
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19e414ac-117a-42ee-a3cf-356128966b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "# let's look at the first 1000 characters\n",
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e23ba358-bc9e-4ee7-9fae-10bca7d3d13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(set(text))\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7da2bcd-a4c5-4366-9471-611be0de9221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(chars)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c588dac3-f449-4528-a000-371009bbd4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_to_int = {}\n",
    "int_to_string = {}\n",
    "\n",
    "for i,ch in enumerate(chars):\n",
    "    int_to_string[i] = ch\n",
    "    string_to_int[ch] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f24ba744-2d61-4426-a5c5-17a8d596820a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(str_data):\n",
    "    encoded_data = []\n",
    "    for d in str_data:\n",
    "        encoded_data.append(string_to_int[d])\n",
    "    return encoded_data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a613e5c1-664a-49e4-95eb-b881afb3b1da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[46, 47, 1, 0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode('hi \\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8432c05-1bbc-48c0-b278-5b8278377fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text_encoded = encode(text)\n",
    "data = torch.tensor(all_text_encoded, dtype = torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "652ae825-101e-414f-bb75-d3076d740f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1115394])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2699c1c-368f-4440-b98e-9f7cf8f0de2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9* len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47d0019a-891c-4e24-8079-e0dd79185d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1003854])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = data[:n]\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c3c47c8-61db-4fab-ad29-bdc1fe477476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([111540])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = data[n:]\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6bde43c-f315-453b-bb13-418aa629548a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100385.40000000001"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.1*n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ecae2da6-0dfd-4680-a1ec-3e3ae070f491",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "context_len = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44faa7ae-4d35-4e7b-899d-f6484c1819b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_batch_data(train_or_test_str):\n",
    "    if train_or_test_str == 'train':\n",
    "        used_data = train_data\n",
    "    else:\n",
    "        used_data = test_data\n",
    "    \n",
    "    batch_beg_idx = torch.randint(0, len(used_data) - context_len, (batch_size,1))\n",
    "    single_batch_data = torch.zeros(batch_size, context_len)\n",
    "    single_batch_data_output = torch.zeros(batch_size, context_len)\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        single_batch_data[i,:] = torch.tensor([ used_data[batch_beg_idx[i] + kk] for kk in range(0,8) ])\n",
    "        single_batch_data_output[i,:] = torch.tensor([ used_data[batch_beg_idx[i] + kk] for kk in range(1,9) ])\n",
    "        \n",
    "    return single_batch_data, single_batch_data_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ea1b1cd-c244-440d-9473-d52876267283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[47., 56., 12.,  0.,  0., 28., 43., 42.],\n",
       "         [42.,  1., 58., 53.,  1., 39., 57., 49.],\n",
       "         [47., 43., 57., 58.,  1., 47., 57.,  1.],\n",
       "         [56.,  1., 19., 56., 43., 51., 47., 53.]]),\n",
       " tensor([[56., 12.,  0.,  0., 28., 43., 42., 39.],\n",
       "         [ 1., 58., 53.,  1., 39., 57., 49.,  1.],\n",
       "         [43., 57., 58.,  1., 47., 57.,  1., 56.],\n",
       "         [ 1., 19., 56., 43., 51., 47., 53.,  6.]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_single_batch_data('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37c2b268-7397-474c-83dc-b45600f2fc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using bag of words to store past context(mean from start to present)\n",
    "B, T, C = 4, 8, 2\n",
    "x = torch.randn(B, T, C)\n",
    "xbow = torch.zeros(B, T, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ba8241c-0d36-44ea-ab4c-690246235ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        x_at_b_t = x[b,:t+1]\n",
    "        # print(torch.mean(x_at_b_t, dim=0).shape)\n",
    "        xbow[b,t,:] = torch.mean(x_at_b_t, dim=0)\n",
    "        # print(x_at_b_t.shape)\n",
    "        # break\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eee2513c-8bcf-41bc-ab9d-0214e50fd3cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6224, -0.0270],\n",
       "        [ 1.4111,  0.2896],\n",
       "        [-1.3121,  0.0160],\n",
       "        [ 1.1322,  0.5791],\n",
       "        [-0.0847,  0.3350],\n",
       "        [-1.2623,  0.8922],\n",
       "        [ 0.0700,  0.3648],\n",
       "        [ 1.1043,  0.7109]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40a225f5-3831-4d93-8c8c-535c8792ce98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4504,  0.2132],\n",
       "        [-0.7731,  0.4824],\n",
       "        [-0.7209,  0.2608],\n",
       "        [-0.7917,  0.2771],\n",
       "        [-0.7492,  0.1327],\n",
       "        [-0.2860, -0.0838],\n",
       "        [-0.2514,  0.0463],\n",
       "        [-0.1560,  0.0522]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb1bff3f-f7d9-44c3-8694-4fd4cbfb4f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# efficient way to perform the above without loops\n",
    "weights = torch.tril(torch.ones(T,T)) # T x T @ T x C = T X C\n",
    "print(weights)\n",
    "weights_norm = weights/weights.sum(1, keepdim=True)\n",
    "weights_norm # T X T \n",
    "xbow_eff = weights_norm @ x # (B) X T X T @ B x T x C = B x T x C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3afe7c4c-b353-4c51-997c-7cfb98312b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.4504,  0.2132],\n",
      "        [-0.7731,  0.4824],\n",
      "        [-0.7209,  0.2608],\n",
      "        [-0.7917,  0.2771],\n",
      "        [-0.7492,  0.1327],\n",
      "        [-0.2860, -0.0838],\n",
      "        [-0.2514,  0.0463],\n",
      "        [-0.1560,  0.0522]])\n",
      "tensor([[-1.4504,  0.2132],\n",
      "        [-0.7731,  0.4824],\n",
      "        [-0.7209,  0.2608],\n",
      "        [-0.7917,  0.2771],\n",
      "        [-0.7492,  0.1327],\n",
      "        [-0.2860, -0.0838],\n",
      "        [-0.2514,  0.0463],\n",
      "        [-0.1560,  0.0522]])\n"
     ]
    }
   ],
   "source": [
    "print(xbow[0])\n",
    "print(xbow_eff[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1862f1c-86fc-4312-a89b-9190a28c602f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now using softmax\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "tril\n",
    "weights_2 = torch.zeros(T,T)\n",
    "weights_2 = weights_2.masked_fill(tril == 0, float('-inf'))\n",
    "weights_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d826a348-e334-41d4-8008-a6bf636299cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_2_s = torch.nn.functional.softmax(weights_2, 1)\n",
    "weights_2_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78318cd2-6180-4f26-81fd-d825540581ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "xbow3 = weights_2_s @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e96ced6f-c2b4-4883-88cd-4485db21697a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.4504,  0.2132],\n",
      "        [-0.7731,  0.4824],\n",
      "        [-0.7209,  0.2608],\n",
      "        [-0.7917,  0.2771],\n",
      "        [-0.7492,  0.1327],\n",
      "        [-0.2860, -0.0838],\n",
      "        [-0.2514,  0.0463],\n",
      "        [-0.1560,  0.0522]])\n",
      "tensor([[-1.4504,  0.2132],\n",
      "        [-0.7731,  0.4824],\n",
      "        [-0.7209,  0.2608],\n",
      "        [-0.7917,  0.2771],\n",
      "        [-0.7492,  0.1327],\n",
      "        [-0.2860, -0.0838],\n",
      "        [-0.2514,  0.0463],\n",
      "        [-0.1560,  0.0522]])\n"
     ]
    }
   ],
   "source": [
    "print(xbow_eff[0])\n",
    "print(xbow3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "90f1408c-8d1a-46dd-9f2c-5cec07796db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5e253f51-eb32-45cd-b6fd-648e163acd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# each token has Query vec(what am I looking for?), Key vec(What do I contain)\n",
    "# A token's Query(what I am looking for?) . Key of Tok1(what I contian?), . Key of Tok2(what i contain?)\n",
    "# head size = len of Query/key vector of each token\n",
    "\n",
    "# but what will be aggregrated is not just input/token directly, but value of token. A new maping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a2c97241-ddee-4dc8-b53a-bf80aa15d27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "B, T, C = 4, 8, 2 # 4 batches, 8 tokens, 2 channels/embedding len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "44638283-1cd6-4709-a827-058ba9bbe6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(B, T, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4ab66d8c-601e-4c0d-9654-4641360c0d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a hyper param for attention block\n",
    "head_size = 16\n",
    "# keys and querys of size = head_size for all tokens, so T x head_size\n",
    "# but it is a linear mapping from (B) x C x head_size . {B} x T X C => T x C @ C x head_size = T x head_size\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "# same way, instead of direct token, another mapping from embedding input to a Value\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bad03f76-46e4-4970-a37b-91313175d3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = query(x)\n",
    "k = key(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9fa63fc6-c139-4940-97e4-b6e71a17101f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "65d3014d-22b2-40e3-b80d-04a3f4d29f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "45acd386-0c9c-4272-93c6-649ff07c9b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_mat = q @ k.transpose(-2,-1) # only last 2 dim, leaving batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c4cad47d-7721-4684-b273-053aa1f2eb72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3302, grad_fn=<VarBackward0>)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_mat.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "103d7eaa-eb1c-4d6a-983d-8f5427903c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_mat = q @ k.transpose(-2, -1) * (head_size**-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c7a9b906-7a4f-41e8-868d-65b28a3600b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.0391e-06, grad_fn=<VarBackward0>)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_mat.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "205bf5e0-9926-4fee-b19b-7817ab7af8ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 8])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c0311c3e-9e5c-4757-a89c-1cc795d8b77f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5004, 0.4996, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3327, 0.3320, 0.3353, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2490, 0.2491, 0.2509, 0.2509, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2003, 0.2005, 0.1990, 0.1989, 0.2013, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1666, 0.1666, 0.1669, 0.1668, 0.1665, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1430, 0.1426, 0.1425, 0.1432, 0.1428, 0.1430, 0.0000],\n",
       "        [0.1250, 0.1251, 0.1248, 0.1248, 0.1252, 0.1250, 0.1251, 0.1251]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# but future tokens can't communicate, so have to make them zero\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "weight_mat = weight_mat.masked_fill(tril == 0, float('-inf'))\n",
    "weight_mat = torch.nn.functional.softmax(weight_mat, -1)\n",
    "weight_mat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4014523a-3801-4f6a-ab0d-cc3f0e862eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final output\n",
    "v = value(x)\n",
    "out = weight_mat @ v\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "043790b4-a68a-415b-b997-db16dfcbc0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. attention can be on any directed graph, like hopfield networks too! \n",
    "# 2. attention need not just be on past, future can also be imposed(that is called encoder block). Here it depends on past, its \n",
    "# called decoder block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4fce33fc-1796-4811-9702-4d9254b825da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5004, 0.4996, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3327, 0.3320, 0.3353, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2490, 0.2491, 0.2509, 0.2509, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2003, 0.2005, 0.1990, 0.1989, 0.2013, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1666, 0.1666, 0.1669, 0.1668, 0.1665, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1430, 0.1426, 0.1425, 0.1432, 0.1428, 0.1430, 0.0000],\n",
       "        [0.1250, 0.1251, 0.1248, 0.1248, 0.1252, 0.1250, 0.1251, 0.1251]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_mat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227ff8ec-a871-45ea-9d68-bf2eb259252c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax when given input as very neg or very pos numbers, the output is very non-uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "69bbcb5d-df0b-4f74-897f-e7924c67b249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9.9995e-01, 4.5398e-05, 2.0611e-09])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "F.softmax(torch.tensor([100., 90., 80.]), dim=0) # max 8 order diff, min 4 order diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5e9b8e9d-5152-40ca-8d7c-9b13be56b080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3672, 0.3322, 0.3006])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(torch.tensor([100., 90., 80.])/100, dim=0) # around 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cc1fed-014e-4449-afd6-c058dfe7ba87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
